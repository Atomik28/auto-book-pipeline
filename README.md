# Automated Book Publication Workflow

**Objective:**  
Create a system to fetch content from a web URL, apply an AI-driven â€œspinâ€ to chapters, allow multiple human-in-the-loop iterations, and manage content versions.

---

## ğŸ“¦ Project Structure

auto-book-pipeline/
â”œâ”€â”€ app.py # Streamlit UI & pipeline orchestration
â”œâ”€â”€ scraper.py # Playwright scraper + screenshot
â”œâ”€â”€ ai_writer.py # AI â€œspinâ€ (Gemini) of raw text
â”œâ”€â”€ ai_reviewer.py # AI review/refinement (Gemini)
â”œâ”€â”€ versioning.py # ChromaDB save/get helpers + version logic
â”œâ”€â”€ pipeline.py # (optional) Python wrapper for full pipeline
â”œâ”€â”€ test.py # CLI to inspect ChromaDB contents
â”œâ”€â”€ output/ # Scraped & processed text + screenshots
â”œâ”€â”€ chroma_db/ # Local ChromaDB persistent store
â”œâ”€â”€ venv/ # Python virtual environment
â”œâ”€â”€ .env # Gemini API key
â””â”€â”€ requirements.txt # Python dependencies

---

## âš™ï¸ Core Capabilities

1. **Scraping & Screenshots**  
   Uses Playwright to fetch chapter text and save a full-page PNG.

2. **AI Writing & Review**  
   - `ai_writer.py` spins (rewrites) each chapter via Google Gemini.  
   - `ai_reviewer.py` refines the spun text for grammar, coherence, readability.

3. **Human-in-the-Loop**  
   Streamlit UI displays Original, Spun, and Reviewed versions in tabs with an editable area for final review.

4. **Agentic API**  
   Each step (scrape, spin, review, version) is exposed as a Python function, and `pipeline.py` wraps them into a single `run_full_pipeline(url, doc_id)` call.

5. **Versioning & Consistency**  
   Uses ChromaDB for persisting all versions with metadata:
   ```json
   {
     "id": "<doc_id>_v<version>_<stage>",
     "document": "<textâ€¦>",
     "metadata": {
       "doc_id": "...",
       "version": n,
       "stage": "...",
       "timestamp": "...",
       "is_final": true|false
     }
   }
Dynamic versioning always picks the next free version.

5. **RL-Like Retrieval**
A simple heuristic in Streamlit sidebar: from all is_final=true versions of a chapter, select the one with the highest version number.

ğŸš€ Quick Start

## âš™ï¸ Setup Instructions

1. **Clone the repo:**
   ```bash
   git clone https://github.com/Atomik28/auto-book-pipeline
   cd auto-book-pipeline

    python3 -m venv venv
    source venv/bin/activate    # On Windows: `venv\Scripts\activate`
    pip install -r requirements.txt
    Add your Gemini API key
    Create a .env file:
    Run the Streamlit app


ğŸ¯ Usage
Step 1: Scrape & Generate

Enter a chapter URL (e.g. Wikisource).

Click Run Scraper & AI Pipeline.

Outputs in output/ and logs in sidebar.

Step 2: Human-in-the-Loop Review

Switch between Original, Spun, and Reviewed tabs.

Edit Reviewed text, then click:

Save Changes â†’ human-edited draft

Re-spin (AI Writer) â†’ AI rewrite

Re-review (AI Reviewer) â†’ AI refinement

Approve & Save to ChromaDB â†’ final version

Step 3: Retrieve Published Chapter

In sidebar â€œRetrieve Published Chapterâ€, pick or enter a doc_id.

Click Get Final Version to display the highest-version final draft.

ğŸ› ï¸ **Inspecting ChromaDB**
Use test.py to dump all IDs & metadata:

    python test.py

ğŸ“ˆ **Future Enhancements**
True RL policy for retrieval (train on user feedback).

FastAPI wrapper for REST-style agent orchestration.

Batch processing of multiple chapters.

Export to ePub/PDF for final publication.

Enjoy your AI-powered book pipeline! Questions or PRs welcome. ğŸš€